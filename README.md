## Hi there ğŸ‘‹


- ğŸ”­ Iâ€™m currently working on end-to-end machine learning project
- ğŸŒ± Iâ€™m currently learning CI/CD pipelines, cloud deployment, Database Integration
- ğŸ‘¯ Iâ€™m looking to collaborate on ML projects
- ğŸ“« How to reach me: https://www.linkedin.com/in/jagapathi-mallepula/
# Hi there, I'm Jagapathi! ğŸ‘‹

**ML Engineer & Deep Learning Enthusiast** ğŸš€

I'm passionate about building intelligent systems that push the boundaries of what's possible with machine learning. From neural networks built from scratch to state-of-the-art fine-tuning techniques, I love exploring the full spectrum of AI development.

## ğŸ”¥ Featured Projects

### ğŸ¨ [ConditionalUNet](https://github.com/jagapathi20/ConditionalUNet)
**Conditional Image Generation with UNet Architecture**
- Built a PyTorch implementation for **polygon coloring** using conditional generation
- Supports 8 different colors with learned color embeddings
- Includes synthetic data generation and comprehensive training pipeline
- **Tech Stack**: PyTorch, OpenCV, Computer Vision, Conditional GANs

### ğŸ§  [Micrograd Implementation](https://github.com/jagapathi20/micrograd-implementation)
**Neural Networks from Scratch with Automatic Differentiation**
- Complete autograd engine implementation with scalar-valued backward pass
- Built MLPs from ground up achieving **95% accuracy** on breast cancer dataset  
- Educational codebase perfect for understanding backpropagation fundamentals
- **Tech Stack**: Python, NumPy, Automatic Differentiation, Neural Networks

### ğŸ” [Advanced RAG Techniques](https://github.com/jagapathi20/advanced-rag-techniques)
**Comprehensive Retrieval-Augmented Generation Implementation**
- Implemented **6+ advanced RAG techniques**: Multi-Query, RAG Fusion, HyDE, RAPTOR
- Built Corrective RAG (CRAG) with web search fallback and relevance grading
- Features query routing, construction, and multi-representation indexing
- **Tech Stack**: LangChain, OpenAI, Vector Databases, LLM Integration

### âš¡ [LLM Fine-tuning with Unsloth](https://github.com/jagapathi20/finetuning)
**High-Performance Language Model Adaptation**
- Fine-tuned LLaMA 3.2-3B with **2x faster training** using Unsloth optimizations
- Achieved efficient training with 4-bit quantization and LoRA (only 0.67% trainable params)
- Complete pipeline from data loading to inference with chat template support
- **Tech Stack**: Unsloth, Transformers, LoRA, CUDA Optimization

## ğŸ› ï¸ Technical Skills

**Deep Learning & AI**
- PyTorch, TensorFlow, Transformers
- Neural Architecture Design, Automatic Differentiation
- Computer Vision, NLP, Generative Models
- Fine-tuning, LoRA, Quantization Techniques

**Machine Learning**
- Supervised/Unsupervised Learning, Model Optimization
- Vector Databases, Retrieval Systems
- AutoML, Hyperparameter Tuning
- Statistical Analysis, Feature Engineering

**Programming & Tools**
- **Languages**: Python, C/C++, SQL
- **MLOps**: Weights & Biases, MLflow
- **Cloud**: Google Colab, AWS
- **Libraries**: NumPy, Pandas, scikit-learn, OpenCV


## ğŸŒŸ Highlights

- **4+ Major Projects** spanning Computer Vision, NLP, and Deep Learning
- **Educational Focus**: Creating implementations that help others learn AI fundamentals
- **Performance Optimization**: Specializing in efficient training and inference techniques
- **End-to-End Solutions**: From data preprocessing to production-ready models



---

*"Building the future with artificial intelligence, one commit at a time."* âœ¨

[![Profile Views](https://komarev.com/ghpvc/?username=jagapathi20&color=blueviolet&style=flat-square)](https://github.com/jagapathi20)
